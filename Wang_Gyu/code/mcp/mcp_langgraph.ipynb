{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 Flow 만들어 가는 중....\n",
    "\n",
    "- 구성 노드 : Vector DB / Neo4j DB / Slack\n",
    "- 노드 선택 여부 : GPT Function Calling\n",
    "- 검색을 위한 질문 재생성 : DeepRetrieval-PubMed-3B\n",
    "- 검색 문서 평가 : LLM as a Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neo4j_retriever': StructuredTool(name='neo4j_retriever', description='\\n    자연어 질문을 임베딩하여 (:Patient.embedding) 벡터 인덱스와 코사인 유사도 Top-k 환자를 반환.\\n    ', args_schema={'properties': {'question': {'title': 'Question', 'type': 'string'}, 'top_k': {'default': 3, 'title': 'Top K', 'type': 'integer'}}, 'required': ['question'], 'title': 'neo4j_retrieverArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f344900>), 'VectorDB_retriever': StructuredTool(name='VectorDB_retriever', args_schema={'properties': {'query': {'title': 'Query', 'type': 'string'}}, 'required': ['query'], 'title': 'VectorDB_retrieverArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f3823e0>), 'slack_list_channels': StructuredTool(name='slack_list_channels', description='List public or pre-defined channels in the workspace with pagination', args_schema={'type': 'object', 'properties': {'limit': {'type': 'number', 'description': 'Maximum number of channels to return (default 100, max 200)', 'default': 100}, 'cursor': {'type': 'string', 'description': 'Pagination cursor for next page of results'}}}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f382f20>), 'slack_post_message': StructuredTool(name='slack_post_message', description='Post a new message to a Slack channel', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel to post to'}, 'text': {'type': 'string', 'description': 'The message text to post'}}, 'required': ['channel_id', 'text']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f3827a0>), 'slack_reply_to_thread': StructuredTool(name='slack_reply_to_thread', description='Reply to a specific message thread in Slack', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel containing the thread'}, 'thread_ts': {'type': 'string', 'description': \"The timestamp of the parent message in the format '1234567890.123456'. Timestamps in the format without the period can be converted by adding the period such that 6 numbers come after it.\"}, 'text': {'type': 'string', 'description': 'The reply text'}}, 'required': ['channel_id', 'thread_ts', 'text']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f382e80>), 'slack_add_reaction': StructuredTool(name='slack_add_reaction', description='Add a reaction emoji to a message', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel containing the message'}, 'timestamp': {'type': 'string', 'description': 'The timestamp of the message to react to'}, 'reaction': {'type': 'string', 'description': 'The name of the emoji reaction (without ::)'}}, 'required': ['channel_id', 'timestamp', 'reaction']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f383880>), 'slack_get_channel_history': StructuredTool(name='slack_get_channel_history', description='Get recent messages from a channel', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel'}, 'limit': {'type': 'number', 'description': 'Number of messages to retrieve (default 10)', 'default': 10}}, 'required': ['channel_id']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f383420>), 'slack_get_thread_replies': StructuredTool(name='slack_get_thread_replies', description='Get all replies in a message thread', args_schema={'type': 'object', 'properties': {'channel_id': {'type': 'string', 'description': 'The ID of the channel containing the thread'}, 'thread_ts': {'type': 'string', 'description': \"The timestamp of the parent message in the format '1234567890.123456'. Timestamps in the format without the period can be converted by adding the period such that 6 numbers come after it.\"}}, 'required': ['channel_id', 'thread_ts']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f382520>), 'slack_get_users': StructuredTool(name='slack_get_users', description='Get a list of all users in the workspace with their basic profile information', args_schema={'type': 'object', 'properties': {'cursor': {'type': 'string', 'description': 'Pagination cursor for next page of results'}, 'limit': {'type': 'number', 'description': 'Maximum number of users to return (default 100, max 200)', 'default': 100}}}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f383920>), 'slack_get_user_profile': StructuredTool(name='slack_get_user_profile', description='Get detailed profile information for a specific user', args_schema={'type': 'object', 'properties': {'user_id': {'type': 'string', 'description': 'The ID of the user'}}, 'required': ['user_id']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x30f3836a0>)}\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated, List, TypedDict, Dict\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_community.document_transformers import LongContextReorder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# 사용 모델들\n",
    "model_client = OpenAI()\n",
    "model = ChatOpenAI(temperature=0.2,\n",
    "                    model_name=\"gpt-4o\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"DeepRetrieval/DeepRetrieval-PubMed-3B\", trust_remote_code=True)\n",
    "# deepretrieval_model = AutoModelForCausalLM.from_pretrained(\"DeepRetrieval/DeepRetrieval-PubMed-3B\", trust_remote_code=True)\n",
    "# deepretrieval_model.to(device)\n",
    "\n",
    "# langgraph state 정의\n",
    "class ChatbotState(TypedDict):\n",
    "    question: Annotated[str, \"Question\"]  \n",
    "    decision_slack: Annotated[str, \"Decision_slack\"]\n",
    "    tools: Annotated[List, \"Tools\"]\n",
    "    tools_query: Annotated[List, \"Tools_Query\"]\n",
    "    # regenerated_question: Annotated[str, \"Regenerated Question\"]\n",
    "    neo4j_documents: Annotated[List, \"Neo4j_Documents\"]  \n",
    "    vector_documents : Annotated[List,\"Vector_Documents\"]\n",
    "    final_answer: Annotated[str, \"Final_Answer\"]  \n",
    "    slack_response: Annotated[str, \"Slack_Response\"]\n",
    "    messages: Annotated[List, add_messages] \n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "# MCP 서버들 불러오기\n",
    "mcp_client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"neo4j_retriever\": {\n",
    "            \"command\": \"/opt/anaconda3/envs/boaz/bin/python\",\n",
    "            \"args\": [\"mcp_neo4j_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        \"VectorDB_retriever\": {\n",
    "            \"command\": \"/opt/anaconda3/envs/boaz/bin/python\",\n",
    "            \"args\": [\"mcp_vectordb_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "        # Slack MCP 서버 설정\n",
    "        \"slack\": {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\n",
    "                \"-y\",\n",
    "                \"@modelcontextprotocol/server-slack\"\n",
    "            ],\n",
    "            \"transport\": \"stdio\", \n",
    "            \"env\": {\n",
    "                \"SLACK_BOT_TOKEN\": os.getenv(\"SLACK_BOT_TOKEN\"),\n",
    "                \"SLACK_TEAM_ID\": os.getenv(\"SLACK_TEAM_ID\"),\n",
    "                # 선택사항: 특정 채널만 접근하려는 경우\n",
    "                \"SLACK_CHANNEL_IDS\": \"C093H2LTEF4\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# MCP 서버 잘 가져왔는지 확인\n",
    "mcp_tools = await mcp_client.get_tools()\n",
    "tools_dict = {tool.name: tool for tool in mcp_tools}\n",
    "print(tools_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "# from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# mcp_client = MultiServerMCPClient(\n",
    "#     {\n",
    "#         # 올바른 Slack MCP 서버 설정\n",
    "#         \"slack\": {\n",
    "#             \"command\": \"npx\",\n",
    "#             \"args\": [\n",
    "#                 \"-y\",\n",
    "#                 \"@modelcontextprotocol/server-slack\"\n",
    "#             ],\n",
    "#             \"transport\": \"stdio\",  # transport 추가 필요\n",
    "#             \"env\": {\n",
    "#                 \"SLACK_BOT_TOKEN\": \n",
    "#                 \"SLACK_TEAM_ID\": \n",
    "#                 # 선택사항: 특정 채널만 접근하려는 경우\n",
    "#                 # \"SLACK_CHANNEL_IDS\": \n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "# tools = await mcp_client.get_tools()\n",
    "\n",
    "# # OpenAI 모델 설정\n",
    "# model_client = OpenAI()\n",
    "\n",
    "# model = ChatOpenAI(temperature=0.2,\n",
    "#                       model_name=\"gpt-4o\")\n",
    "\n",
    "# # 에이전트 생성\n",
    "# agent = create_react_agent(model, tools)\n",
    "\n",
    "# # 에이전트에게 자연어로 지시 -> 채널명 지정 필요\n",
    "# response = await agent.ainvoke({\n",
    "#     \"messages\": [{\n",
    "#         \"role\": \"user\",\n",
    "#         \"content\": (\n",
    "#             \"백지연의 다이렉트 메시\"\n",
    "#             \"slack_post_message 툴을 사용해.\"\n",
    "#         )\n",
    "#     }]\n",
    "# })\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_calling_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"neo4j_retriever\",\n",
    "        \"description\": \"\"\"Use this tool when the user's query is explicitly about patient-specific \n",
    "            clinical information or refers to structured medical records.\n",
    "\n",
    "            This includes queries containing terms such as: \n",
    "            '환자', '환자정보', '환자기록', '환자이력', '환자데이터', '환자상태', \n",
    "            '수술이력', '검사기록', '진료기록', '입원', '퇴원', '복용약물',\n",
    "            '진단', '수술명', '마취제', '마취제 유형', '수술 전 상태', '수술 후 상태'.\n",
    "\n",
    "            These queries typically require retrieving structured data from graph-based \n",
    "            medical records (e.g., Neo4j) related to an individual patient or to specific \n",
    "            clinical procedures.\n",
    "\n",
    "            This tool is designed to access and return relevant information such as:\n",
    "            surgery history, diagnoses, anesthesia types used, pre- and post-operative conditions, \n",
    "            medication usage, lab results, and hospitalization records.\n",
    "\n",
    "            Use this tool when the question involves:\n",
    "            - Specific patients\n",
    "            - Specific treatments or surgeries\n",
    "            - Named diagnoses or procedures\n",
    "            - Clinical state before/after operations\n",
    "\n",
    "            Do not use this tool for general medical knowledge, non-clinical topics, or \n",
    "            queries unrelated to structured or relational patient data.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"\"\"Please write the query as a natural language question about the patient's clinical records.\n",
    "\n",
    "                    The query will be interpreted to explore nodes (e.g., Surgery, Anesthesia, Diagnosis, Patient) and their relationships (e.g., surgeries received by a specific patient) in a graph database.\n",
    "\n",
    "                    For example, the question \"Tell me the name of the most recent surgery and the anesthesia used\" will be processed as a query exploring connections between Surgery and Anesthesia nodes.\n",
    "\n",
    "                    Also, the question \"Tell me the pre-operative condition and diagnosis of patient Hong Gil-dong\" will be interpreted as a query that finds the Person node with the name 'Hong Gil-dong' and extracts the related Pre-op condition and Diagnosis nodes.\n",
    "\n",
    "                    If a patient name is specified, please write the query to retrieve not only that patient but also other patients with similar symptoms.\n",
    "\n",
    "                    If no patient name is given, please write the query to search for patients matching the symptoms, surgery names, or diagnoses mentioned in the question.\n",
    "\n",
    "                    The more specific the patient information or clinical conditions included, the more accurately the relevant data can be retrieved.\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"VectorDB_retriever\",\n",
    "        \"description\": \"\"\"BrokenPipeErrorUse this tool when the user's query involves general clinical or medical knowledge that is not tied to a specific patient.\n",
    "\n",
    "                This includes queries containing medical or procedural terms such as:\n",
    "                surgery names (e.g., \"cholecystectomy\", \"cardiac surgery\"), anesthesia types (e.g., \"general anesthesia\", \"local anesthesia\"), medications, clinical processes, or treatment guidelines.\n",
    "\n",
    "                Example queries:\n",
    "                - \"How does general anesthesia work?\"\n",
    "                - \"What are common complications of this surgery?\"\n",
    "                - \"What anesthetics are typically used in pediatric patients?\"\n",
    "\n",
    "                These types of queries are interpreted as requests for background medical knowledge or conceptual explanations. The tool retrieves semantically relevant information from a vector-based medical knowledge database.\n",
    "\n",
    "                Do not use this tool for patient-specific record queries or when structured relational data is needed, such as diagnosis timelines or surgical histories.\"\"\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"\"\"Construct a query that focuses on general medical or clinical knowledge, excluding any patient-specific details.\n",
    "\n",
    "                The query should be based on concepts extracted from the user's original question, such as surgery names, anesthesia types, diagnoses, medications, or treatment processes.\n",
    "\n",
    "                For example, if the user asks \"What kind of anesthesia was used for Kim's surgery?\", the query should be reformulated as \"What types of anesthesia are commonly used for that kind of surgery?\"\n",
    "\n",
    "                Avoid including patient names, identifiers, or individual medical histories. Focus on retrieving background information or typical medical explanations that are generally applicable.\"\"\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "            \"additionalProperties\": False\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_SYSTEM_PROMPTY = \"\"\"\n",
    "# INSTRUCTION\n",
    "당신은 의료 데이터에 특화된 전문가 AI입니다.\n",
    "사용자의 질문에 대해 다음 두 가지 출처의 정보를 참고하여 답변을 생성하세요:\n",
    "\n",
    "1. 🔎 Neo4j 검색 결과: 구조화된 환자 관련 정보 (예: 수술 이력, 검사 기록 등)\n",
    "2. 📚 VectorDB 검색 결과: 일반적인 의학 지식 (예: 증상 설명, 치료 가이드라인 등)\n",
    "\n",
    "- 두 결과 모두 존재할 경우, 각 출처를 구분하여 통합적으로 반영하되, 중복 내용은 요약하거나 통합하세요.\n",
    "- 한 쪽의 결과만 존재할 경우, 해당 결과만을 바탕으로 답변하되, 정보의 한계에 대해 언급하지 말고 최대한 성실히 답변하세요.\n",
    "- 결과가 너무 적거나 애매하더라도 반드시 유의미한 설명을 제공하려고 노력하세요.\n",
    "- 불필요한 서론 없이, 질문에 바로 답변하세요.\n",
    "\n",
    "# Neo4j CONTEXT\n",
    "{Neo4j}\n",
    "\n",
    "# Vector DB CONTEXT\n",
    "{VectorDB}\n",
    "\n",
    "# Question\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# LLM_REGENERATED_QUESTION = \"\"\"\n",
    "# You are a helpful assistant specialized in pediatric anesthesia. \n",
    "# You first think about the reasoning process in your mind and then rewrite the user’s question into a more effective form for document retrieval. \n",
    "# Your task is to convert user questions into concise, keyword-based queries suitable for sparse vector-based search in a pediatric anesthesia knowledge base.\n",
    "\n",
    "# Show your thought process in <think> </think> tags.  \n",
    "# Your final response must be in JSON format within <answer> </answer> tags.  \n",
    "# For example:  \n",
    "# <answer>  \n",
    "# {{  \n",
    "#   \"query\": \"...\"  \n",
    "# }}  \n",
    "# </answer>\n",
    "\n",
    "# Note: You may use Boolean operators (AND, OR) and parentheses when needed to group terms.\n",
    "\n",
    "# Here’s the user’s question related to pediatric anesthesia:  \n",
    "# {question}\n",
    "\n",
    "# Assistant: Let me think step by step.  \n",
    "# <think>\n",
    "# \"\"\"\n",
    "\n",
    "LLM_DECISION_SLACK = \"\"\"\n",
    "You are a decision-making assistant for Slack dispatch.\n",
    "If the user asks to send a message or question to a specific person via Slack (e.g., '~에게 보내줘', '~에게 전송해줘'),\n",
    "respond with \"Yes\".\n",
    "Otherwise, respond with \"No\".\n",
    "\n",
    "Only respond with \"Yes\" or \"No\". Do not include any explanation or formatting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"query\":\"A환자 정보 알려줘\"}', call_id='call_bYFRVMgTLp5Zsn4IvBqKKgam', name='neo4j_retriever', type='function_call', id='fc_68602cba820081a299158122efc8e342043d4b3d165b18d0', status='completed'), ResponseFunctionToolCall(arguments='{\"query\":\"감기에 대해 알려줘\"}', call_id='call_9HTmUVu93LJdBYryHvo5fjdU', name='VectorDB_retriever', type='function_call', id='fc_68602cba9d3881a29cd165a36bf0e5e9043d4b3d165b18d0', status='completed')]\n"
     ]
    }
   ],
   "source": [
    "# import json\n",
    "\n",
    "# question = \"A환자 정보와 감기에 대해서 알려줘\"\n",
    "\n",
    "# input_messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"Decide which tools to use to answer the user's question. You may call one or both.\"},\n",
    "#     {\"role\": \"user\", \"content\": question}\n",
    "# ]\n",
    "\n",
    "# response = model_client.responses.create(model=\"gpt-4.1\",\n",
    "#                                             input=input_messages,\n",
    "#                                             tools=tools)\n",
    "# print(response.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m input_text = LLM_REGENERATED_QUESTION.format(question = question)\n\u001b[32m      4\u001b[39m inputs = tokenizer(input_text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m outputs = \u001b[43mdeepretrieval_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m                            \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m response = tokenizer.decode(outputs[\u001b[32m0\u001b[39m], skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/transformers/generation/utils.py:2465\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, **kwargs)\u001b[39m\n\u001b[32m   2457\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2458\u001b[39m         input_ids=input_ids,\n\u001b[32m   2459\u001b[39m         expand_size=generation_config.num_return_sequences,\n\u001b[32m   2460\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2461\u001b[39m         **model_kwargs,\n\u001b[32m   2462\u001b[39m     )\n\u001b[32m   2464\u001b[39m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2465\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2470\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2471\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2472\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2473\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2476\u001b[39m     \u001b[38;5;66;03m# 11. interleave input_ids with `num_beams` additional sequences per batch\u001b[39;00m\n\u001b[32m   2477\u001b[39m     input_ids, model_kwargs = \u001b[38;5;28mself\u001b[39m._expand_inputs_for_generation(\n\u001b[32m   2478\u001b[39m         input_ids=input_ids,\n\u001b[32m   2479\u001b[39m         expand_size=generation_config.num_beams,\n\u001b[32m   2480\u001b[39m         is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2481\u001b[39m         **model_kwargs,\n\u001b[32m   2482\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/transformers/generation/utils.py:3476\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   3474\u001b[39m     probs = nn.functional.softmax(next_token_scores, dim=-\u001b[32m1\u001b[39m)\n\u001b[32m   3475\u001b[39m     \u001b[38;5;66;03m# TODO (joao): this OP throws \"skipping cudagraphs due to ['incompatible ops']\", find solution\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3476\u001b[39m     next_tokens = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m.squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m   3477\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3478\u001b[39m     next_tokens = torch.argmax(next_token_scores, dim=-\u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# question = \"Kasabach-Merrritt Syndrome이 뭐야?\"\n",
    "\n",
    "# input_text = LLM_REGENERATED_QUESTION.format(question = question)\n",
    "# inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "# outputs = deepretrieval_model.generate(**inputs, \n",
    "#                             max_new_tokens=100,\n",
    "#                             temperature = 0.6)\n",
    "# response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.chat_models import ChatOpenAI\n",
    "# import re\n",
    "\n",
    "# model = ChatOpenAI(temperature=0.2, model_name=\"gpt-4o\")\n",
    "\n",
    "# LLM_DECISION_SLACK = \"\"\"\n",
    "# You are a decision-making assistant for Slack dispatch.\n",
    "# If the user asks to send a message or question to a specific person via Slack (e.g., '~에게 보내줘', '~에게 전송해줘'),\n",
    "# respond with \"yes\".\n",
    "# Otherwise, respond with \"no\".\n",
    "\n",
    "# Only respond with \"yes\" or \"no\". Do not include any explanation or formatting.\n",
    "# \"\"\"\n",
    "\n",
    "# SEND_COMMANDS = [\"보내줘\", \"전송해줘\"]\n",
    "\n",
    "# def determine_slack_usage(query: str) -> str:\n",
    "#     pattern = re.compile(r\"(.+?)에게\\s*(.+?)\\s*(?:Slack으로\\s*)?(보내줘|전송해줘)\")\n",
    "#     m = pattern.search(query)\n",
    "#     return 'Yes' if m else 'No'\n",
    "\n",
    "# def decision_tools(question: str):\n",
    "#     user_query = question\n",
    "\n",
    "#     # 1) Rule-based 판단\n",
    "#     use_slack = determine_slack_usage(user_query)\n",
    "#     response = use_slack\n",
    "\n",
    "#     # 2) 명확하지 않은 경우 → LLM 판단\n",
    "#     if use_slack == 'No' and (\"에게\" in user_query or any(cmd in user_query for cmd in SEND_COMMANDS)):\n",
    "#         llm_response = model.invoke(f\"{LLM_DECISION_SLACK}\\n\\n{user_query}\")\n",
    "        \n",
    "#         response = llm_response\n",
    "#     print(response)\n",
    "#     return response\n",
    "\n",
    "# # 테스트\n",
    "# decision_tools(question=\"윤왕규 간호사한테 'hi' 메세지 전달해줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# SEND_COMMANDS = [\"보내줘\", \"전송해줘\", \"전달해줘\"]\n",
    "\n",
    "# def determine_slack_usage(query: str) -> str:\n",
    "#     command_pattern = \"|\".join(SEND_COMMANDS)  \n",
    "#     pattern = re.compile(rf\"(.+?)에게\\s*(.+?)\\s*(?:Slack으로\\s*)?({command_pattern})\")\n",
    "#     m = pattern.search(query)\n",
    "#     return 'Yes' if m else 'No'\n",
    "\n",
    "# def determine_slack_usage(query: str) -> str:\n",
    "#     return 'Yes' if any(cmd in query for cmd in SEND_COMMANDS) else 'No'\n",
    "\n",
    "# async def decision_slack(state: ChatbotState):\n",
    "#     user_query = state[\"question\"]\n",
    "\n",
    "#     # 1) Rule-based 판단\n",
    "#     use_slack = determine_slack_usage(user_query)\n",
    "#     response = use_slack  # 기본값 설정\n",
    "\n",
    "#     # 2) 패턴은 일부 있지만 명확하지 않은 경우 → LLM 판단\n",
    "#     if use_slack.lower() == 'no' and (\"에게\" in user_query or any(cmd in user_query for cmd in SEND_COMMANDS)):\n",
    "#         llm_response = await model.ainvoke(f\"{LLM_DECISION_SLACK}\\n\\n{user_query}\")\n",
    "#         response = llm_response\n",
    "\n",
    "#     return ChatbotState(decision_slack=response)\n",
    "\n",
    "async def decision_tools(state: ChatbotState):\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "\n",
    "    input_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"Decide which tools to use to answer the user's question. You may call one or both.\"},\n",
    "        {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "    \n",
    "    response = model_client.responses.create(model=\"gpt-4.1\",\n",
    "                                             input=input_messages,\n",
    "                                             tools=function_calling_tools)\n",
    "    \n",
    "    tools_name = [tool.name for tool in response.output]\n",
    "    tools_query = [json.loads(call.arguments)[\"query\"] for call in response.output]\n",
    "\n",
    "    return ChatbotState(tools=tools_name,\n",
    "                        tools_query=tools_query)\n",
    "\n",
    "async def neo4j_to_vectordb(state: ChatbotState):\n",
    "    \"\"\"\n",
    "    ① Neo4j → ② VectorDB 순서로 호출하고\n",
    "    두 결과를 모두 state에 저장.\n",
    "    \"\"\"\n",
    "    # ---- ① Neo4j -------------------------------------------------\n",
    "    question = next(\n",
    "        q for t, q in zip(state[\"tools\"], state[\"tools_query\"])\n",
    "        if t == \"neo4j_retriever\"\n",
    "    )\n",
    "\n",
    "    neo4j_tool = tools_dict[\"neo4j_retriever\"]\n",
    "    neo_res = await neo4j_tool.ainvoke({\"question\": question, \"top_k\": 3})\n",
    "\n",
    "    # ---- ② VectorDB (Neo4j 결과로 쿼리 확장) ----------------------\n",
    "    vec_tool  = tools_dict[\"VectorDB_retriever\"]\n",
    "    expanded_query = f\"{question}\\n\\nGRAPH_CONTEXT:\\n{neo_res}\"\n",
    "    vec_res = await vec_tool.ainvoke({\"query\": expanded_query, \"top_k\": 5})\n",
    "\n",
    "    # LangGraph는 “부분 딕셔너리”만 돌려주면 기존 state와 merge\n",
    "    return ChatbotState(neo4j_documents = neo_res, \n",
    "                        vector_documents = vec_res)\n",
    "\n",
    "async def vector_db(state: ChatbotState):\n",
    "    question = None\n",
    "    for tool, q in zip(state[\"tools\"], state[\"tools_query\"]):\n",
    "        if tool == \"VectorDB_retriever\":\n",
    "            question = q\n",
    "            break\n",
    "\n",
    "    # 질문 재생성\n",
    "    # input_text = LLM_REGENERATED_QUESTION.format(question = question)\n",
    "    # inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    # outputs = model.generate(**inputs, \n",
    "    #                          max_new_tokens=500,\n",
    "    #                          temperature = 0.6)\n",
    "    # response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            \n",
    "    vectordb_tool = tools_dict[\"VectorDB_retriever\"]\n",
    "        \n",
    "    result = await vectordb_tool.ainvoke({\"query\": question})\n",
    "\n",
    "    return ChatbotState(vector_documents=result,\n",
    "                        # regenerated_question=response\n",
    "                        )\n",
    "\n",
    "async def neo4j_db(state: ChatbotState):\n",
    "    question = None\n",
    "    for tool, q in zip(state[\"tools\"], state[\"tools_query\"]):\n",
    "        if tool == \"neo4j_retriever\":\n",
    "            question = q\n",
    "            break\n",
    "    \n",
    "    neo4j_tool = tools_dict.get(\"neo4j_retriever\")\n",
    "    \n",
    "    # result = await neo4j_tool.ainvoke({\"query\": question})\n",
    "    result = await neo4j_tool.ainvoke({\n",
    "        \"question\": question,   # ← 필수\n",
    "        \"top_k\": 3              # ← 생략 가능, 기본 3\n",
    "    })\n",
    "\n",
    "    return ChatbotState(neo4j_documents=result)\n",
    "\n",
    "# 여기서 질문 + 검색 문서 넣고 예쁘게 프롬프트\n",
    "async def merge_outputs(state:ChatbotState):\n",
    "\n",
    "    question = state['question']\n",
    "    vector_documents = state['vector_documents']\n",
    "    neo4j_documents = state['neo4j_documents']\n",
    "\n",
    "    slack_state = state['decision_slack']\n",
    "\n",
    "    formatted = LLM_SYSTEM_PROMPTY.format(Neo4j = neo4j_documents,\n",
    "                                          VectorDB = vector_documents,\n",
    "                                          question = question)\n",
    "    response = await model.ainvoke(formatted)\n",
    "    final_response_text = response.content if isinstance(response, AIMessage) else str(response)\n",
    "\n",
    "    # 위에서 slack 보냄 여부가 'Yes'이면 LLM 최종 답변을 Slack으로 보내기\n",
    "    if slack_state.lower() == 'yes':\n",
    "        tools = await mcp_client.get_tools()\n",
    "        agent = create_react_agent(model, tools)\n",
    "        content = f\"백지연이 속해 있는 채널에 {final_response_text} 보내줘. slack_post_message 툴을 써.\"\n",
    "        slack_response = await agent.ainvoke({\"messages\": [{\"role\": \"user\",\n",
    "                                                    \"content\": content}]})                                                                                                                                                                       \n",
    "    return ChatbotState(final_answer=final_response_text,\n",
    "                        # slack_response=slack_response,\n",
    "                        messages=[(\"user\", question), (\"assistant\", final_response_text)])\n",
    "\n",
    "# async def join_node(state: ChatbotState):\n",
    "#     return state  # 단순히 결과만 모아서 넘김\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x30f3d8f90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder = StateGraph(ChatbotState)\n",
    "\n",
    "# builder.add_node(\"slack\", decision_slack)\n",
    "builder.add_node(\"decision_tools\", decision_tools)\n",
    "builder.add_node(\"neo4j_to_vectordb\", neo4j_to_vectordb)\n",
    "# builder.add_node(\"join_node\", join_node)\n",
    "builder.add_node(\"vector_db\", vector_db)\n",
    "builder.add_node(\"neo4j_db\", neo4j_db)\n",
    "builder.add_node(\"merge_outputs\", merge_outputs)\n",
    "\n",
    "builder.add_edge(START, \"decision_tools\")\n",
    "# builder.add_edge(START, \"slack\")\n",
    "\n",
    "# builder.add_edge(\"slack\", \"join_node\")\n",
    "# builder.add_edge(\"decision_tools\", \"join_node\")\n",
    "\n",
    "def route_tools(state: ChatbotState):\n",
    "    return state[\"tools\"]\n",
    "\n",
    "# builder.add_conditional_edges(\n",
    "#     \"decision_tools\",\n",
    "#     route_tools,\n",
    "#     {\n",
    "#         \"neo4j_retriever\": \"neo4j_db\",\n",
    "#         \"VectorDB_retriever\": \"vector_db\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "# builder.add_conditional_edges(\n",
    "#     \"join_node\",\n",
    "#     route_tools,\n",
    "#     {\n",
    "#         \"neo4j_retriever\": \"neo4j_db\",\n",
    "#         \"VectorDB_retriever\": \"vector_db\"\n",
    "#     }\n",
    "# )\n",
    "\n",
    "builder.add_edge(\"decision_tools\",\"neo4j_db\")\n",
    "builder.add_edge(\"decision_tools\",\"vector_db\")\n",
    "builder.add_edge(\"decision_tools\",\"neo4j_to_vectordb\")\n",
    "builder.add_edge(\"neo4j_db\", \"merge_outputs\")\n",
    "builder.add_edge(\"vector_db\", \"merge_outputs\")\n",
    "builder.add_edge(\"neo4j_to_vectordb\", \"merge_outputs\")\n",
    "builder.add_edge(\"merge_outputs\", END)\n",
    "\n",
    "builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'decision_tools': {'tools': ['neo4j_retriever'], 'tools_query': ['오른손 합지증 분리술 수술을 받은 사람의 이름을 알려줘.']}}\n",
      "{'slack': {'decision_slack': 'Yes'}}\n",
      "{'join_node': {'question': '오른손 합지증 분리술 수술을 받은 사람의 이름을 찾고 slack으로 전달해줘.', 'decision_slack': 'Yes', 'tools': ['neo4j_retriever'], 'tools_query': ['오른손 합지증 분리술 수술을 받은 사람의 이름을 알려줘.'], 'neo4j_documents': [], 'vector_documents': [], 'final_answer': '', 'slack_response': '', 'messages': []}}\n"
     ]
    },
    {
     "ename": "ToolException",
     "evalue": "Error executing tool neo4j_retriever: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.vector.similarity.matchNodes` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mToolException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     10\u001b[39m initial_state = {\n\u001b[32m     11\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,\n\u001b[32m     12\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdecision_slack\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     19\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [],\n\u001b[32m     20\u001b[39m }\n\u001b[32m     22\u001b[39m events = []\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m graph.astream(initial_state, config=config):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(event)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langgraph/pregel/__init__.py:2759\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2753\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2754\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   2755\u001b[39m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2756\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2757\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   2758\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2759\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2760\u001b[39m         loop.tasks.values(),\n\u001b[32m   2761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2762\u001b[39m         retry_policy=\u001b[38;5;28mself\u001b[39m.retry_policy,\n\u001b[32m   2763\u001b[39m         get_waiter=get_waiter,\n\u001b[32m   2764\u001b[39m     ):\n\u001b[32m   2765\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2766\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   2767\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 82\u001b[39m, in \u001b[36mneo4j_db\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     79\u001b[39m neo4j_tool = tools_dict.get(\u001b[33m\"\u001b[39m\u001b[33mneo4j_retriever\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# result = await neo4j_tool.ainvoke({\"query\": question})\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m neo4j_tool.ainvoke({\n\u001b[32m     83\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: question,   \u001b[38;5;66;03m# ← 필수\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtop_k\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m3\u001b[39m              \u001b[38;5;66;03m# ← 생략 가능, 기본 3\u001b[39;00m\n\u001b[32m     85\u001b[39m })\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ChatbotState(neo4j_documents=result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/structured.py:66\u001b[39m, in \u001b[36mStructuredTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine:\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# If the tool does not implement async, fall back to default implementation\u001b[39;00m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m run_in_executor(config, \u001b[38;5;28mself\u001b[39m.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/base.py:523\u001b[39m, in \u001b[36mBaseTool.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    515\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    516\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mainvoke\u001b[39m(\n\u001b[32m    517\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    520\u001b[39m     **kwargs: Any,\n\u001b[32m    521\u001b[39m ) -> Any:\n\u001b[32m    522\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m523\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.arun(tool_input, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/base.py:887\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    886\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    889\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/base.py:856\u001b[39m, in \u001b[36mBaseTool.arun\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    853\u001b[39m         tool_kwargs[config_param] = config\n\u001b[32m    855\u001b[39m     coro = \u001b[38;5;28mself\u001b[39m._arun(*tool_args, **tool_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m coro_with_context(coro, context)\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    858\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_core/tools/structured.py:110\u001b[39m, in \u001b[36mStructuredTool._arun\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.coroutine):\n\u001b[32m    109\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.coroutine(*args, **kwargs)\n\u001b[32m    112\u001b[39m \u001b[38;5;66;03m# If self.coroutine is None, then this will delegate to the default\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[38;5;66;03m# implementation which is expected to delegate to _run on a separate thread.\u001b[39;00m\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()._arun(\n\u001b[32m    115\u001b[39m     *args, config=config, run_manager=run_manager, **kwargs\n\u001b[32m    116\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_mcp_adapters/tools.py:105\u001b[39m, in \u001b[36mconvert_mcp_tool_to_langchain_tool.<locals>.call_tool\u001b[39m\u001b[34m(**arguments)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    104\u001b[39m     call_tool_result = \u001b[38;5;28;01mawait\u001b[39;00m session.call_tool(tool.name, arguments)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_call_tool_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_tool_result\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/boaz/lib/python3.11/site-packages/langchain_mcp_adapters/tools.py:43\u001b[39m, in \u001b[36m_convert_call_tool_result\u001b[39m\u001b[34m(call_tool_result)\u001b[39m\n\u001b[32m     40\u001b[39m     tool_content = tool_content[\u001b[32m0\u001b[39m]\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call_tool_result.isError:\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ToolException(tool_content)\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tool_content, non_text_contents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mToolException\u001b[39m: Error executing tool neo4j_retriever: {code: Neo.ClientError.Procedure.ProcedureNotFound} {message: There is no procedure with the name `db.vector.similarity.matchNodes` registered for this database instance. Please ensure you've spelled the procedure name correctly and that the procedure is properly deployed.}",
      "During task with name 'neo4j_db' and id '7bbfa055-34ba-0beb-9f49-69aa3cfcb301'"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": 1})\n",
    "\n",
    "# question = \"Kasabach-Merrritt Syndrome에 대해서 조사하고 slack으로 전달해줘.\"\n",
    "question = \"오른손 합지증 분리술 수술을 받은 사람의 이름을 찾고 slack으로 전달해줘.\"\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "initial_state = {\n",
    "    \"question\": question,\n",
    "    \"decision_slack\":\"\",\n",
    "    \"tools\": [],\n",
    "    \"tools_query\" : [],\n",
    "    \"neo4j_documents\": [],\n",
    "    \"vector_documents\": [],\n",
    "    \"final_answer\": \"\",\n",
    "    \"slack_response\":\"\",\n",
    "    \"messages\": [],\n",
    "}\n",
    "\n",
    "events = []\n",
    "async for event in graph.astream(initial_state, config=config):\n",
    "    print(event)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boaz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
